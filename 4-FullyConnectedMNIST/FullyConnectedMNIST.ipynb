{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST: Fully Connected network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy, torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data.dataloader as dataloader\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from matplotlib.colors import Colormap\n",
    "\n",
    "SEED = 1\n",
    "\n",
    "# CUDA?\n",
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "# For reproducibility\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "if cuda:\n",
    "    torch.cuda.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = MNIST('/tmp/data', train=True, download=True, transform=transforms.Compose([\n",
    "    transforms.ToTensor(), # ToTensor does min-max normalization \n",
    "]), )\n",
    "\n",
    "test = MNIST('/tmp/data', train=False, download=True, transform=transforms.Compose([\n",
    "    transforms.ToTensor(), # ToTensor does min-max normalization\n",
    "]), )\n",
    "\n",
    "# Create DataLoader\n",
    "dataloader_args = dict(shuffle=True, batch_size=256,num_workers=4, pin_memory=True) if cuda else dict(shuffle=True, batch_size=64)\n",
    "train_loader = dataloader.DataLoader(train, **dataloader_args)\n",
    "test_loader = dataloader.DataLoader(test, **dataloader_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    \"\"\"\n",
    "    Fully-connected model, with one hidden layer.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    fc : torch.nn.modules.linear.Linear\n",
    "        The first fully-connected layer.\n",
    "    fc2 : torch.nn.modules.linear.Linear\n",
    "        The second fully connected layer.\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> model = Model()\n",
    "    >>> if cuda:\n",
    "    ...     model.cuda()\n",
    "    >>>> optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Creation of the model.\n",
    "        \"\"\"\n",
    "        super(Model, self).__init__()\n",
    "        self.fc = nn.Linear(784, 1000)\n",
    "        self.fc2 = nn.Linear(1000, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        A forward pass in the model.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.nn_like\n",
    "            The input of the model.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        out : torch.nn_like\n",
    "            The output of the model.\n",
    "        \n",
    "        Notes\n",
    "        -----\n",
    "        This function as not to be call directly.\n",
    "        \"\"\"\n",
    "        x = x.view((-1, 784))\n",
    "        h = F.relu(self.fc(x))\n",
    "        h = self.fc2(h)\n",
    "        return F.log_softmax(h, dim=0)    \n",
    "    \n",
    "    \n",
    "model = Model()\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "losses = []\n",
    "\n",
    "# Eval\n",
    "evaluate_x = Variable(test_loader.dataset.test_data.type_as(torch.FloatTensor()))\n",
    "evaluate_y = Variable(test_loader.dataset.test_labels)\n",
    "if cuda:\n",
    "    evaluate_x, evaluate_y = evaluate_x.cuda(), evaluate_y.cuda()\n",
    "train_size = len(train_loader.dataset)\n",
    "batch_size = (train_size / 256) if (cuda) else  (train_size / 64)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(EPOCHS):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # Get Samples\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        \n",
    "        if cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        \n",
    "        # Init\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Predict\n",
    "        y_pred = model(data) \n",
    "\n",
    "        # Calculate loss\n",
    "        loss = F.cross_entropy(y_pred, target)\n",
    "        losses.append(loss.cpu().item())\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Display\n",
    "        if batch_idx % 100 == 1:\n",
    "            print('\\r Train Epoch: {}/{} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch+1,\n",
    "                EPOCHS,\n",
    "                batch_idx * len(data), \n",
    "                train_size,\n",
    "                100. * batch_idx / batch_size, \n",
    "                loss.cpu().item()), \n",
    "                end='')\n",
    "\n",
    "    # display final evaluation for this epoch\n",
    "    model.eval()\n",
    "    output = model(evaluate_x)\n",
    "    pred = output.data.max(1)[1]\n",
    "    d = pred.eq(evaluate_y.data).cpu()\n",
    "    accuracy = d.sum().item()/d.size()[0]\n",
    "    \n",
    "    print('\\r Train Epoch: {}/{} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\t Test Accuracy: {:.4f}%'.format(\n",
    "        epoch+1,\n",
    "        EPOCHS,\n",
    "        train_size, \n",
    "        train_size,\n",
    "        100. * batch_idx / batch_size, \n",
    "        loss.cpu().item(),\n",
    "        accuracy*100,\n",
    "        end=''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "output = model(evaluate_x)\n",
    "pred = output.data.max(1)[1]\n",
    "d = pred.eq(evaluate_y.data).cpu()\n",
    "accuracy = d.sum().item()/d.size()[0]\n",
    "print('Accuracy: {}%'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
