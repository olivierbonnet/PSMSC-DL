{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A classification of images of the game 'Rock, Paper, Scissors'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to classify the images of the game 'Rock, Paper, Scissors' into three sets: Rock, Paper and Scissors. It will be done using a quite simple neural network algorithm (Feed Forward, one hidden layer), implemented with the Python package Torch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etablishment of the system "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, numpy, torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data.dataloader as dataloader\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms, datasets\n",
    "from PIL import Image\n",
    "\n",
    "SEED = 1\n",
    "\n",
    "# Is CUDA available?\n",
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "# For reproducibility\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "if cuda:\n",
    "    torch.cuda.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of the next code is to fill the 'Test' folder, with 20% of the images of the 'Train' folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "PW=\"./img\"  # The current path\n",
    "\n",
    "# If the Test folder is not empty then move all files in the Train folder\n",
    "FE=$(find $PW/Test -name \"*\" -type f)\n",
    "if [ -z \"$FE\" ]; then\n",
    "    echo \"Initial Test folder creation.\"\n",
    "else\n",
    "    echo \"Test folder re-creation.\"\n",
    "    T_IMG=$(find $PW/Test -name \"*.jpg\" -type f)  # A list of the tests images\n",
    "    \n",
    "    for f in $T_IMG; do\n",
    "        mv $f $(echo $f | sed 's/Test/Train/')  # Move into Train directory\n",
    "    done\n",
    "fi\n",
    "\n",
    "# Create the Test folder\n",
    "IMG=$(find $PW/Train -name \"*.jpg\" -type f | shuf)  # A list of the images\n",
    "LEN=$(echo -e $IMG | wc -w)  # The length of the IMG\n",
    "T_RATE=\"0.2\"  # The rate of test images\n",
    "\n",
    "# A list of random FILES with theirs paths\n",
    "FILES=$(echo -e $IMG | tr \" \" \"\\n\" | tail -n $(echo $LEN*$T_RATE | bc | awk -F '.' '{ print $1 }'))\n",
    "\n",
    "for f in $FILES; do\n",
    "    mv $f $(echo $f | sed 's/Train/Test/')  # Move into Test directory\n",
    "done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now import the data in the notebook and create the dataloader. However, for this first exemple, no data augmentation and complex preprocessing have been done. The main objective of this work is just to implement an operational algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dataset\n",
    "\n",
    "path = './img'\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.Grayscale(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(20, resample=Image.BILINEAR),\n",
    "    transforms.ToTensor(), # ToTensor does min-max normalization.\n",
    "])\n",
    "train = datasets.ImageFolder(os.path.join(path,'Train'), transform=transform)\n",
    "test = datasets.ImageFolder(os.path.join(path,'Test'), transform=transform)\n",
    "\n",
    "# Create the dataloader\n",
    "dataloader_args = dict(shuffle=True, batch_size=20, num_workers=4, pin_memory=True)\n",
    "train_loader = dataloader.DataLoader(train, **dataloader_args)\n",
    "dataloader_args = dict(shuffle=True, batch_size=len(test), num_workers=4, pin_memory=True)\n",
    "test_loader = dataloader.DataLoader(test, **dataloader_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The neural network algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of the one-hidden-layer feed-forward network.\n",
    "class Model(nn.Module):\n",
    "    \"\"\"\n",
    "    Fully-connected model, with one hidden layer.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    fc : torch.nn.modules.linear.Linear\n",
    "        The first fully-connected layer.\n",
    "    fc2 : torch.nn.modules.linear.Linear\n",
    "        The second fully connected layer.\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> model = Model()\n",
    "    >>> if cuda:\n",
    "    ...     model.cuda()\n",
    "    >>>> optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Creation of the model.\n",
    "        \"\"\"\n",
    "        super(Model, self).__init__()\n",
    "        self.fc = nn.Linear(1024, 1000)  # The size of the images are 32*32 = 1024\n",
    "        self.fc2 = nn.Linear(1000, 3)  # There are 3 differents classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        A forward pass in the model.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.nn_like\n",
    "            The input of the model.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        out : torch.nn_like\n",
    "            The output of the model.\n",
    "        \n",
    "        Notes\n",
    "        -----\n",
    "        This function as not to be call directly.\n",
    "        \"\"\"\n",
    "        x = x.view((-1, 1024))\n",
    "        h = torch.relu(self.fc(x))\n",
    "        h = self.fc2(h)\n",
    "        return F.log_softmax(h, dim=0)    \n",
    "    \n",
    "    \n",
    "model = Model()\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "EPOCHS = 15\n",
    "losses = []\n",
    "\n",
    "# Evaluation of the loader\n",
    "evaluate = iter(test_loader)\n",
    "evaluate_x, evaluate_y = evaluate.next()\n",
    "if cuda:\n",
    "    evaluate_x, evaluate_y = evaluate_x.cuda(), evaluate_y.cuda()\n",
    "\n",
    "train_size = len(train_loader.dataset)\n",
    "batch_size = 7  #(train_size / 256) if (cuda) else (train_size / 64)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(EPOCHS):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # Get samples\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        if cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        \n",
    "        # Initialization\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Predict\n",
    "        y_pred = model(data) \n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = F.cross_entropy(y_pred, target)\n",
    "        losses.append(loss.cpu().item())\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Display\n",
    "        if batch_idx % 100 == 1:\n",
    "            print('\\r Train Epoch: {}/{} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch+1,\n",
    "                EPOCHS,\n",
    "                batch_idx * len(data), \n",
    "                train_size,\n",
    "                100. * batch_idx / batch_size, \n",
    "                loss.cpu().item()), \n",
    "                end='')\n",
    "\n",
    "    # Display final evaluation for this epoch\n",
    "    model.eval()\n",
    "    output = model(evaluate_x)\n",
    "    pred = output.data.max(1)[1]\n",
    "    d = pred.eq(evaluate_y.data).cpu()\n",
    "    accuracy = d.sum().item()/d.size()[0]\n",
    "    \n",
    "    print('\\r Train Epoch: {}/{} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\t Test Accuracy: {:.4f}%'.format(\n",
    "        epoch+1,\n",
    "        EPOCHS,\n",
    "        train_size, \n",
    "        train_size,\n",
    "        100. * batch_idx / batch_size, \n",
    "        loss.cpu().item(),\n",
    "        accuracy*100,\n",
    "        end=''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparameters has been chosen almost randomly. For instance, 15 epochs are enough to test the validity of our network : There are 3 classes and the test accuracy is greater than 33%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
